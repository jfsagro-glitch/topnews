"""
DeepSeek API client for AI summarization.
OPTIMIZED: Uses caching, budget guard, optimized prompts.
"""
from __future__ import annotations

import asyncio
import os
import logging
import uuid
from typing import Optional

import httpx

from config.config import (
    DEEPSEEK_API_ENDPOINT, 
    AI_SUMMARY_TIMEOUT,
    DEEPSEEK_INPUT_COST_PER_1K_TOKENS_USD,
    DEEPSEEK_OUTPUT_COST_PER_1K_TOKENS_USD
)
from utils.text_cleaner import truncate_text

logger = logging.getLogger(__name__)

MAX_INPUT_CHARS = 3500


def _truncate_input(text: str, max_chars: int = MAX_INPUT_CHARS) -> str:
    if not text:
        return ""
    if len(text) <= max_chars:
        return text
    return truncate_text(text, max_chars)


def _estimate_tokens(text: str) -> int:
    if not text:
        return 0
    return max(1, len(text) // 4)


def _build_messages(title: str, text: str) -> list[dict]:
    # Ð¢Ñ‹ â€” Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¾Ñ€ Ñ€Ð°Ð´Ð¸Ð¾Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ (Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ñ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸ÐµÐ¹ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°)
    system_prompt = (
        "Ð¢Ñ‹ â€” Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¾Ñ€ Ñ€Ð°Ð´Ð¸Ð¾Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹.\n\n"
        "ÐŸÐµÑ€ÐµÐ¿Ð¸ÑˆÐ¸ Ð½Ð¾Ð²Ð¾ÑÑ‚ÑŒ, ÑÑ‚Ñ€Ð¾Ð³Ð¾ ÑÐ¾Ð±Ð»ÑŽÐ´Ð°Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°:\n"
        "1. ÐÐ°Ñ‡Ð½Ð¸ Ñ Ð¾Ð´Ð½Ð¾Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾Ð¹ Ñ„Ñ€Ð°Ð·Ñ‹ Ð´Ð¾ 7 ÑÐ»Ð¾Ð², Ð¿ÐµÑ€ÐµÐ´Ð°ÑŽÑ‰ÐµÐ¹ ÑÑƒÑ‚ÑŒ\n"
        "2. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¸Ð· Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°\n"
        "3. ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð´Ð¾Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ð¸ Ð½Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð¾Ñ‚ ÑÐµÐ±Ñ\n"
        "4. Ð£Ð´Ð°Ð»Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ñ‹, ÑÑÑ‹Ð»ÐºÐ¸ Ð¸ Ð²Ñ‚Ð¾Ñ€Ð¾ÑÑ‚ÐµÐ¿ÐµÐ½Ð½Ñ‹Ðµ Ð´ÐµÑ‚Ð°Ð»Ð¸\n"
        "5. ÐžÐ±ÑŠÑ‘Ð¼: 100â€“150 ÑÐ»Ð¾Ð² (30â€“40 ÑÐµÐºÑƒÐ½Ð´ Ð¿Ñ€Ð¸ Ñ‡Ñ‚ÐµÐ½Ð¸Ð¸ Ð²ÑÐ»ÑƒÑ…)\n"
        "6. ÐšÐ°Ð¶Ð´Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ â€” Ð½Ðµ Ð´Ð»Ð¸Ð½Ð½ÐµÐµ 12 ÑÐ»Ð¾Ð²\n"
        "7. ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð»ÐµÐ³ÐºÐ¾ Ð¿Ñ€Ð¾Ð¸Ð·Ð½Ð¾ÑÐ¸Ñ‚ÑŒÑÑ Ð²ÑÐ»ÑƒÑ…\n"
        "8. ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð´ÐµÐµÐ¿Ñ€Ð¸Ñ‡Ð°ÑÑ‚Ð¸Ñ, Ð¿Ñ€Ð¸Ñ‡Ð°ÑÑ‚Ð¸Ñ Ð¸ Ð¿Ð°ÑÑÐ¸Ð²Ð½Ñ‹Ð¹ Ð·Ð°Ð»Ð¾Ð³\n"
        "9. ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÐºÐ°Ð½Ñ†ÐµÐ»ÑÑ€Ð¸Ð·Ð¼Ñ‹ Ð¸ Ñ„Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¼Ñ‹\n"
        "10. Ð¡Ñ‚Ð¸Ð»ÑŒ â€” ÑÑƒÑ…Ð¾Ð¹, Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹, Ñ€Ð°Ð´Ð¸Ð¾Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸\n"
        "11. ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¾Ñ†ÐµÐ½ÐºÑƒ. Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ñ„Ð°ÐºÑ‚Ñ‹\n"
        "12. ÐŸÑ€ÑÐ¼Ñ‹Ðµ Ñ†Ð¸Ñ‚Ð°Ñ‚Ñ‹, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ, Ð¿Ñ€Ð¸Ð²Ð¾Ð´Ð¸ Ð´Ð¾ÑÐ»Ð¾Ð²Ð½Ð¾ Ð² ÐºÐ°Ð²Ñ‹Ñ‡ÐºÐ°Ñ…\n"
        "13. Ð’ ÐºÐ¾Ð½Ñ†Ðµ ÑƒÐºÐ°Ð¶Ð¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ (Ð±ÐµÐ· ÑÑÑ‹Ð»ÐºÐ¸)\n\n"
        "Ð•ÑÐ»Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ â€” ÑÐ´ÐµÐ»Ð°Ð¹ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð¿ÐµÑ€ÐµÑÐºÐ°Ð· Ð±ÐµÐ· Ð´Ð¾Ð¼Ñ‹ÑÐ»Ð¾Ð²."
    )
    user_content = f"Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº: {title}\n\nÐ¢ÐµÐºÑÑ‚: {text}"
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content},
    ]


def _build_category_messages(title: str, text: str, current_category: str) -> list[dict]:
    """Build messages for AI category verification"""
    system_prompt = (
        "Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÐ¼. "
        "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰ÑƒÑŽ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸.\n\n"
        "ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸:\n"
        "- moscow: Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¾ Ð³Ð¾Ñ€Ð¾Ð´Ðµ ÐœÐ¾ÑÐºÐ²Ðµ (ÑÑ‚Ð¾Ð»Ð¸Ñ†Ð°, ÐšÑ€ÐµÐ¼Ð»ÑŒ, Ð¼ÑÑ€ Ð¡Ð¾Ð±ÑÐ½Ð¸Ð½, Ð¼Ð¾ÑÐºÐ¾Ð²ÑÐºÐ¸Ðµ Ð²Ð»Ð°ÑÑ‚Ð¸, ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð’ ÐœÐ¾ÑÐºÐ²Ðµ)\n"
        "- moscow_region: Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¾ ÐœÐ¾ÑÐºÐ¾Ð²ÑÐºÐ¾Ð¹ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸/ÐŸÐ¾Ð´Ð¼Ð¾ÑÐºÐ¾Ð²ÑŒÐµ (Ð³Ð¾Ñ€Ð¾Ð´Ð° ÐœÐž, Ð³ÑƒÐ±ÐµÑ€Ð½Ð°Ñ‚Ð¾Ñ€ ÐœÐž, ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð² Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸)\n"
        "- world: Ð¼ÐµÐ¶Ð´ÑƒÐ½Ð°Ñ€Ð¾Ð´Ð½Ñ‹Ðµ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ (Ð´Ñ€ÑƒÐ³Ð¸Ðµ ÑÑ‚Ñ€Ð°Ð½Ñ‹, Ð·Ð°Ñ€ÑƒÐ±ÐµÐ¶Ð½Ñ‹Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ, Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ°)\n"
        "- russia: Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¾ Ð Ð¾ÑÑÐ¸Ð¸ Ð² Ñ†ÐµÐ»Ð¾Ð¼ (Ñ„ÐµÐ´ÐµÑ€Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÐ°, Ñ€ÐµÐ³Ð¸Ð¾Ð½Ñ‹ Ð Ð¤ ÐºÑ€Ð¾Ð¼Ðµ ÐœÐ¾ÑÐºÐ²Ñ‹/ÐœÐž, Ñ€Ð¾ÑÑÐ¸Ð¹ÑÐºÐ¸Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ)\n\n"
        "Ð¢ÐµÐºÑƒÑ‰Ð°Ñ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ: {current_category}\n\n"
        "Ð’ÐÐ–ÐÐž: ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð¢ÐžÐ›Ð¬ÐšÐž Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ Ð¾Ð´Ð½Ð¸Ð¼ ÑÐ»Ð¾Ð²Ð¾Ð¼: moscow, moscow_region, world Ð¸Ð»Ð¸ russia. "
        "ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹ Ð¸Ð»Ð¸ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°."
    )
    user_content = f"Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº: {title}\n\nÐ¢ÐµÐºÑÑ‚: {text[:1000]}"
    return [
        {"role": "system", "content": system_prompt.format(current_category=current_category)},
        {"role": "user", "content": user_content},
    ]


def _build_text_extraction_messages(title: str, raw_text: str) -> list[dict]:
    """Build messages for AI text extraction (removing navigation/garbage)"""
    system_prompt = (
        "Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ñ‡Ð¸ÑÑ‚Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¸Ð· HTML.\n\n"
        "Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°: Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ ÑÐ°Ð¼Ð¾Ð¹ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸, ÑƒÐ´Ð°Ð»Ð¸Ð²:\n"
        "- Ð¡Ð¿Ð¸ÑÐºÐ¸ Ð³Ð¾Ñ€Ð¾Ð´Ð¾Ð² (Ð‘Ð°Ð»Ð°ÑˆÐ¸Ñ…Ð° Ð‘Ð¾Ð³Ð¾Ñ€Ð¾Ð´ÑÐºÐ¸Ð¹ Ð’Ð¾ÑÐºÑ€ÐµÑÐµÐ½ÑÐº...)\n"
        "- ÐÐ°Ð²Ð¸Ð³Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ð¼ÐµÐ½ÑŽ (ÐšÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð° Ð’ÑÐµ ÐšÐ¸Ð½Ð¾ Ð¡ÐµÑ€Ð¸Ð°Ð»Ñ‹, Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð­Ñ„Ð¸Ñ€...)\n"
        "- Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ (Ð¨Ð¾ÐºÐ¸Ñ€ÑƒÑŽÑ‰Ð¸Ðµ Ð¾Ñ‚ÐºÑ€Ð¾Ð²ÐµÐ½Ð¸Ñ...)\n"
        "- Ð”ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ° (ÐµÑÐ»Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÐµÑ‚ÑÑ 2-3 Ñ€Ð°Ð·Ð°)\n"
        "- Ð ÐµÐºÐ»Ð°Ð¼Ñƒ Ð¸ ÑÑÑ‹Ð»ÐºÐ¸\n\n"
        "Ð’ÐµÑ€Ð½Ð¸ 1-2 Ð°Ð±Ð·Ð°Ñ†Ð° Ñ Ñ„Ð°ÐºÑ‚Ð°Ð¼Ð¸ Ð¾ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¸, ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð¼ Ð² Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐµ. ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹."
    )
    user_content = f"Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº: {title}\n\nÐ˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚:\n{raw_text[:3500]}"
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content},
    ]


class DeepSeekClient:
    def __init__(self, api_key: str = None, endpoint: str = DEEPSEEK_API_ENDPOINT, db=None):
        self.api_key = api_key if api_key and api_key.strip() else None
        self.endpoint = endpoint
        self.db = db
        
        # Initialize cache and budget managers if DB provided
        self.cache = None
        self.budget = None
        if db:
            try:
                from net.llm_cache import LLMCacheManager, BudgetGuard
                self.cache = LLMCacheManager(db)
                self.budget = BudgetGuard(db, daily_limit_usd=float(os.getenv('DAILY_LLM_BUDGET_USD', '1.0')))
                logger.info("âœ… LLM cache and budget guard enabled")
            except Exception as e:
                logger.warning(f"Failed to initialize LLM cache/budget: {e}")
        
        env_key_at_init = os.getenv('DEEPSEEK_API_KEY')
        logger.info(
            f"DeepSeekClient initialized. "
            f"Env DEEPSEEK_API_KEY exists: {env_key_at_init is not None}, "
            f"Env var length: {len(env_key_at_init) if env_key_at_init else 0}, "
            f"Cache: {self.cache is not None}, Budget guard: {self.budget is not None}"
        )

    async def summarize(self, title: str, text: str, level: int = 3) -> tuple[Optional[str], dict]:
        request_id = str(uuid.uuid4())[:8]
        
        # Check if AI level is 0 (disabled)
        if level == 0:
            logger.info(f"[{request_id}] â­ï¸ AI summary disabled (level=0)")
            return None, {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0, "cache_hit": False, "disabled": True}
        
        # Get LLM profile for level
        from core.services.access_control import get_llm_profile
        profile = get_llm_profile(level, 'summary')
        logger.debug(f"[{request_id}] Using AI level {level}: {profile.get('description', 'N/A')}")
        
        # Check budget limit
        if self.budget and not self.budget.can_make_request():
            logger.warning(f"[{request_id}] âŒ Daily budget exceeded, skipping LLM call")
            return None, {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0, "cache_hit": False, "budget_exceeded": True}
        
        # Check cache
        if self.cache:
            cache_key = self.cache.generate_cache_key('summarize', title, text, level=level)
            cached = self.cache.get(cache_key)
            if cached:
                logger.info(f"[{request_id}] âœ… Cache HIT for summarize")
                return cached['response'], {
                    "input_tokens": cached['input_tokens'],
                    "output_tokens": cached['output_tokens'],
                    "total_tokens": cached['input_tokens'] + cached['output_tokens'],
                    "cache_hit": True
                }
        
        # Always try to read API key from environment first (for Railway support)
        env_key = os.getenv('DEEPSEEK_API_KEY')
        api_key = (env_key or self.api_key or '').strip()
        
        if not api_key:
            logger.error(
                f"[{request_id}] âŒ DeepSeek API key not configured! "
                f"Env DEEPSEEK_API_KEY exists: {env_key is not None}, "
                f"Env var empty: {env_key == ''}, "
                f"Instance key set: {bool(self.api_key)}. "
                f"Please add DEEPSEEK_API_KEY to environment variables."
            )
            return None, {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0, "cache_hit": False}

        text = _truncate_input(text)
        if not text:
            return None, {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0, "cache_hit": False}

        payload = {
            "model": profile.get('model', 'deepseek-chat'),
            "messages": _build_messages(title, text),
            "temperature": profile.get('temperature', 0.7),
            "max_tokens": profile.get('max_tokens', 800),
        }
        
        # Add optional parameters
        if 'top_p' in profile:
            payload['top_p'] = profile['top_p']
        
        logger.info(f"[{request_id}] ðŸ”„ API call: summarize (level={level}, max_tokens={payload['max_tokens']})")

        backoff = 0.8
        for attempt in range(1, 4):
            try:
                async with httpx.AsyncClient(timeout=AI_SUMMARY_TIMEOUT) as client:
                    response = await client.post(
                        self.endpoint,
                        headers={"Authorization": f"Bearer {api_key}"},
                        json=payload,
                    )
                if response.status_code == 200:
                    data = response.json()
                    summary = data["choices"][0]["message"]["content"]
                    usage = data.get("usage", {})
                    
                    # Get separate token counts for accurate pricing
                    input_tokens = int(usage.get("prompt_tokens", 0) or 0)
                    output_tokens = int(usage.get("completion_tokens", 0) or 0)
                    total_tokens = int(usage.get("total_tokens", 0) or 0)
                    
                    if total_tokens == 0:
                        total_tokens = _estimate_tokens(text)
                        input_tokens = total_tokens
                        output_tokens = 0
                    
                    # Calculate cost and update budget
                    cost_usd = (input_tokens * DEEPSEEK_INPUT_COST_PER_1K_TOKENS_USD / 1000 +
                                output_tokens * DEEPSEEK_OUTPUT_COST_PER_1K_TOKENS_USD / 1000)
                    
                    if self.budget:
                        self.budget.add_cost(cost_usd)
                    
                    logger.info(f"[{request_id}] âœ… summarize: {input_tokens}+{output_tokens}={total_tokens} tokens, ${cost_usd:.4f}")
                    
                    # Store in cache
                    result_text = truncate_text(summary.strip(), max_length=800)
                    if self.cache:
                        cache_key = self.cache.generate_cache_key('summarize', title, text, level=level)
                        self.cache.set(cache_key, 'summarize', result_text, input_tokens, output_tokens, cost_usd)
                    
                    # Return summary and token usage dict
                    token_usage = {
                        "input_tokens": input_tokens,
                        "output_tokens": output_tokens,
                        "total_tokens": total_tokens,
                        "cache_hit": False,
                        "cost_usd": cost_usd
                    }
                    return result_text, token_usage

                try:
                    error_data = response.json()
                    error_msg = error_data.get('error', {}).get('message', response.text[:500])
                    logger.error(
                        f"DeepSeek API error: status={response.status_code}, "
                        f"error={error_msg}, attempt={attempt}/3"
                    )
                except:
                    logger.error(
                        f"DeepSeek API error: status={response.status_code}, "
                        f"response={response.text[:500]}, attempt={attempt}/3"
                    )
            except (httpx.TimeoutException, asyncio.TimeoutError):
                logger.warning(f"DeepSeek API timeout (attempt {attempt}/3)")
            except Exception as e:
                logger.error(f"DeepSeek API exception (attempt {attempt}/3): {e}")

            await asyncio.sleep(backoff)
            backoff *= 2

        return None, {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}

    async def verify_category(self, title: str, text: str, current_category: str) -> tuple[Optional[str], dict]:
        """
        Verify and potentially correct news category using AI.
        
        Args:
            title: Article title
            text: Article text (will be truncated)
            current_category: Current category from keyword classifier
            
        Returns:
            Tuple of (verified category name or None, token usage dict)
        """
        token_usage = {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}
        
        env_key = os.getenv('DEEPSEEK_API_KEY')
        api_key = (env_key or self.api_key or '').strip()
        
        if not api_key:
            logger.debug("DeepSeek API key not configured, skipping AI category verification")
            return None, token_usage

        text = _truncate_input(text, max_chars=1000)
        if not text:
            return None, token_usage

        payload = {
            "model": "deepseek-chat",
            "messages": _build_category_messages(title, text, current_category),
            "temperature": 0.3,  # Lower temperature for more deterministic classification
            "max_tokens": 20,
        }

        try:
            async with httpx.AsyncClient(timeout=5.0) as client:  # Shorter timeout for classification
                response = await client.post(
                    self.endpoint,
                    headers={"Authorization": f"Bearer {api_key}"},
                    json=payload,
                )
            
            if response.status_code == 200:
                data = response.json()
                category = data["choices"][0]["message"]["content"].strip().lower()
                
                # Extract token usage
                usage = data.get("usage", {})
                token_usage = {
                    "input_tokens": usage.get("prompt_tokens", 0),
                    "output_tokens": usage.get("completion_tokens", 0),
                    "total_tokens": usage.get("total_tokens", 0)
                }
                
                # Validate response
                valid_categories = ['moscow', 'moscow_region', 'world', 'russia']
                if category in valid_categories:
                    if category != current_category:
                        logger.info(f"AI corrected category: {current_category} -> {category}")
                    return category, token_usage
                else:
                    logger.warning(f"AI returned invalid category: {category}")
                    return None, token_usage
            
            logger.warning(f"DeepSeek category API error: status={response.status_code}")
            
        except Exception as e:
            logger.debug(f"AI category verification failed: {e}")
        
        return None, token_usage
    
    async def extract_clean_text(self, title: str, raw_text: str) -> tuple[Optional[str], dict]:
        """
        Use AI to extract clean article text, removing navigation/garbage.
        
        Args:
            title: Article title
            raw_text: Raw extracted text with possible garbage
            
        Returns:
            Tuple of (clean article text or None, token usage dict)
        """
        token_usage = {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}
        
        env_key = os.getenv('DEEPSEEK_API_KEY')
        api_key = (env_key or self.api_key or '').strip()
        
        if not api_key:
            logger.debug("DeepSeek API key not configured, skipping AI text extraction")
            return None, token_usage

        if not raw_text or len(raw_text) < 50:
            return None, token_usage

        payload = {
            "model": "deepseek-chat",
            "messages": _build_text_extraction_messages(title, raw_text),
            "temperature": 0.2,  # Low temperature for consistent extraction
            "max_tokens": 500,  # Allow up to 3-4 paragraphs for better context
        }

        try:
            async with httpx.AsyncClient(timeout=8.0) as client:
                response = await client.post(
                    self.endpoint,
                    headers={"Authorization": f"Bearer {api_key}"},
                    json=payload,
                )
            
            if response.status_code == 200:
                data = response.json()
                clean_text = data["choices"][0]["message"]["content"].strip()
                
                # Extract token usage
                usage = data.get("usage", {})
                token_usage = {
                    "input_tokens": usage.get("prompt_tokens", 0),
                    "output_tokens": usage.get("completion_tokens", 0),
                    "total_tokens": usage.get("total_tokens", 0)
                }
                
                # Validate that we got meaningful text
                if clean_text and len(clean_text) >= 50:
                    logger.debug(f"AI extracted clean text: {len(clean_text)} chars")
                    return clean_text, token_usage
                else:
                    logger.debug("AI extraction returned text too short")
                    return None, token_usage
            
            logger.warning(f"DeepSeek text extraction API error: status={response.status_code}")
            
        except Exception as e:
            logger.debug(f"AI text extraction failed: {e}")
        
        return None, token_usage
